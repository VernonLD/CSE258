{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "    for l in urllib.urlopen(fname):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseDataFromFile(fname):\n",
    "    for l in open(fname):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print \"Reading data...\"\n",
    "# data1 = list(parseDataFromFile(\"/Users/Vernonld/Desktop/book_images_5000.json\"))\n",
    "data2 = list(parseDataFromFile(\"/Users/Vernonld/Desktop/beer_50000.json\"))\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "For the reason that question 8 uses the basic model of Q5, so I move the program and answer of Q5 below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "Considering the ‘American IPA’ style, can you come up with a more accurate predictor (e.g. using features from the text, or otherwise)? Write down the feature vector you design, and report its train/test accuracy (1 mark).\n",
    "\n",
    "I added the feature from the text like 'caramel' or 'amber', both are the typical feature of American IPA. Therefore I think these two features could be ideal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Question 6 & Question7\n",
    "def feature(datum):\n",
    "    feat = [1, datum['beer/ABV'], datum['review/taste'], datum['beer/brewerId']]\n",
    "    if 'caramel' in datum['review/text'] and 'amber' in datum['review/text'] and 'grapefruit' in datum['review/text']:\n",
    "        feat.append(1)\n",
    "    else:\n",
    "        feat.append(0)\n",
    "    return feat\n",
    "\n",
    "X = [feature(b) for b in data2]\n",
    "y = [\"American IPA\" in b['beer/style'] for b in data2]\n",
    "\n",
    "X_train = X[:25000]\n",
    "y_train = y[:25000]\n",
    "\n",
    "X_test = X[25000:]\n",
    "y_test = y[25000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a support vector classifier object, with regularization parameter C = 1000\n",
    "clf = svm.SVC(C=10, kernel = 'linear')  #Penalty parameter C of the error term.\n",
    "clf.fit(X_train, y_train)\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9136 0.92188\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = sum([t == p for t,p in zip(y_train,train_predictions)]) * 1.0/25000\n",
    "accuracy_test  = sum([t == p for t,p in zip(y_test,  test_predictions)]) * 1.0/25000\n",
    "print accuracy_train,accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question7\n",
    "What effect does the regularization constant C have on the training/test performance? Report the train/test accuracy of your predictor from the previous question for C ∈ ⟨0.1, 10, 1000, 100000⟩.\n",
    "\n",
    "Penalty parameter C of the error term. The C parameter trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly by giving the model freedom to select more samples as support vectors.\n",
    "\n",
    "The lower C required less running time compare to a higher C, and accuracy of the model may increase with the increase of parameter c. But if the feature we choose already make the model accurate enough, then the accuracy would not increase unless we choose new features.\n",
    "\n",
    "c = 0.1    accuracy_train = 0.9136   accuracy_test = 0.92188\n",
    "\n",
    "c = 10     accuracy_train = 0.9136   accuracy_test = 0.92188\n",
    "\n",
    "c = 1000   accuracy_train = 0.9136  accuracy_test = 0.92188\n",
    "\n",
    "c = 100000 accuracy_train = 0.9136  accuracy_test = 0.92188\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question5\n",
    "First, let’s train a predictor that estimates whether a beer is an ‘American IPA’ using two features: [‘beer/ABV’, ‘review/taste’].\n",
    "Train your predictor using an SVM classifier (see the code provided in class) – remember to train on the first half and test on the second half. Use a regularization constant of C = 1000 as in the code stub. What is the accuracy (percentage of correct classifications) of the predictor on the train and test data? (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###TAST 5\n",
    "def feature(datum):\n",
    "    feat = [1, datum['beer/ABV'], datum['review/taste']]\n",
    "    return feat\n",
    "\n",
    "X = [feature(b) for b in data2]\n",
    "y = [\"American IPA\" in b['beer/style'] for b in data2]\n",
    "\n",
    "X_train = X[:25000]\n",
    "y_train = y[:25000]\n",
    "\n",
    "X_test = X[25000:]\n",
    "y_test = y[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a support vector classifier object, with regularization parameter C = 1000\n",
    "clf = svm.SVC(C=1000,kernel = 'linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = clf.predict(X_train)\n",
    "test_predictions = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9128 0.92112\n"
     ]
    }
   ],
   "source": [
    "#Question5 accuracy\n",
    "accuracy_train = sum([t == p for t,p in zip(y_train,train_predictions)]) * 1.0/25000\n",
    "accuracy_test  = sum([t == p for t,p in zip(y_test,  test_predictions)]) * 1.0/25000\n",
    "print accuracy_train,accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "Finally, let’s fit a model (for the problem from Q5) using logistic regression. A code stub has been provided to perform logistic regression using the above model on http://jmcauley.ucsd.edu/ cse258/code/homework1.py Code for the log-likelihood has been provided in the code stub (f) but code for the derivative is incomplete (fprime)\n",
    "Complete the code stub for the derivative (fprime) and provide your solution. What is the log-likelihood of after convergence, and what is the accuracy (on the test set) of the resulting model (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Question 8\n",
    "import numpy\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from math import exp\n",
    "from math import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inner(x,y):\n",
    "    return sum([x[i]*y[i] for i in range(len(x))])\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEGATIVE Log-likelihood\n",
    "def f(theta, X, y, lam):\n",
    "    loglikelihood = 0\n",
    "    for i in range(len(X)):\n",
    "        logit = inner(X[i], theta)\n",
    "        loglikelihood -= log(1 + exp(-logit))\n",
    "        if not y[i]:\n",
    "            loglikelihood -= logit\n",
    "    for k in range(len(theta)):\n",
    "        loglikelihood -= lam * theta[k]*theta[k]\n",
    "    print \"ll =\", loglikelihood\n",
    "    return -loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEGATIVE Derivative of log-likelihood\n",
    "def fprime(theta, X, y, lam):\n",
    "    dl = [0.0]*len(theta)\n",
    "    for k in range(len(theta)):\n",
    "        logit_d = 0\n",
    "        for i in range(len(X)):\n",
    "        # Fill in code for the derivative\n",
    "            logit = inner(X[i], theta)\n",
    "            logit_d += X[i][k] * (1 - sigmoid(logit))\n",
    "            if not y[i]:\n",
    "                logit_d -= X[i][k]\n",
    "        logit_d -= 2 * lam * theta[k]\n",
    "        dl[k] = logit_d\n",
    "    # Negate the return value since we're doing gradient *ascent*\n",
    "    return numpy.array([-x for x in dl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = [1, datum['beer/ABV'], datum['review/taste']]\n",
    "    return feat\n",
    "\n",
    "X = [feature(b) for b in data2]\n",
    "y = [\"American IPA\" in b['beer/style'] for b in data2]\n",
    "\n",
    "X_train = X[:len(X)/2]\n",
    "X_test = X[len(X)/2:]\n",
    "# If we wanted to split with a validation set:\n",
    "#X_valid = X[len(X)/2:3*len(X)/4]\n",
    "#X_test = X[3*len(X)/4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ll = -17328.679514\n",
      "ll = -16341.2013892\n",
      "ll = -13952.6362653\n",
      "ll = -6951.99741346\n",
      "ll = -7358.42557314\n",
      "ll = -6910.14444961\n",
      "ll = -6906.4039954\n",
      "ll = -6892.46364043\n",
      "ll = -6803.17967996\n",
      "ll = -6787.73594284\n",
      "ll = -6783.12927193\n",
      "ll = -6782.88180995\n",
      "ll = -6782.29658661\n",
      "ll = -6780.5430371\n",
      "ll = -6776.38750021\n",
      "ll = -6766.5473173\n",
      "ll = -6747.07517193\n",
      "ll = -6718.50759263\n",
      "ll = -6888.22077896\n",
      "ll = -6716.20422105\n",
      "ll = -6695.66660154\n",
      "ll = -6691.5816811\n",
      "ll = -6690.85883334\n",
      "ll = -6690.83165269\n",
      "ll = -6690.83160231\n",
      "ll = -6690.83159755\n",
      "Final log likelihood = -6690.83159755\n",
      "[-1.77315687 -0.4530953   0.67198756]\n"
     ]
    }
   ],
   "source": [
    "# Use a library function to run gradient descent (or you can implement yourself!)\n",
    "theta,l,info = scipy.optimize.fmin_l_bfgs_b(f, [0]*len(X[0]), fprime, args = (X_train, y_train, 1.0))\n",
    "print \"Final log likelihood =\", -l\n",
    "print theta\n",
    "theta = numpy.matrix(theta)\n",
    "#print \"Accuracy = \" # Compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92188\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "def predict(X, theta):\n",
    "    X = numpy.matrix(X_test)\n",
    "    y_pred = X_test * theta.T\n",
    "    for y in y_pred:\n",
    "        if y < 0:\n",
    "            yield False\n",
    "test_predictions = list(predict(X_test, theta))\n",
    "accuracy_test  = sum([t == p for t,p in zip(y_test,  test_predictions)]) * 1.0/25000\n",
    "print accuracy_test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
